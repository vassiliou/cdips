{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import skimage\n",
    "from skimage import io, feature, measure, transform\n",
    "import tensorflow as tf\n",
    "from pandas import Series,DataFrame\n",
    "import sampling as smp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reduce(image, scale=4):\n",
    "    reducedimage = transform.pyramid_reduce(image, downscale=scale)\n",
    "    return reducedimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training = pd.read_msgpack('training.bin')\n",
    "non_empty_training = training[~training.maskC.isnull()]\n",
    "non_empty_training.index=np.arange(len(non_empty_training))\n",
    "centers = non_empty_training.maskC.as_matrix()\n",
    "center_list=np.array([tuple(c) for c in centers])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training_centers=center_list[0:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### crop image to 80 x 136 to make the numbers rounder for the nn..\n",
    "def build_training_data(num_images):\n",
    "    data=[]\n",
    "    for i in range(num_images):\n",
    "        if i%100 ==0:\n",
    "            print 'Reading patch ', i\n",
    "        ultra_image = smp.image_pair(non_empty_training.ix[i].subject,non_empty_training.ix[i].img).image\n",
    "        data.append(reduce(ultra_image)[25:,:136].flatten())\n",
    "    return np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading patch  0\n",
      "Reading patch  100\n",
      "Reading patch  200\n",
      "Reading patch  300\n",
      "Reading patch  400\n",
      "Reading patch  500\n",
      "Reading patch  600\n",
      "Reading patch  700\n",
      "Reading patch  800\n",
      "Reading patch  900\n",
      "CPU times: user 1min 4s, sys: 5.01 s, total: 1min 9s\n",
      "Wall time: 1min 17s\n"
     ]
    }
   ],
   "source": [
    "time X=build_training_data(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sess=tf.InteractiveSession()\n",
    "\n",
    "### use 4x reduced images as input features\n",
    "x= tf.placeholder(tf.float32,shape=[None, 10880])\n",
    "x_image = tf.reshape(x, [-1,80,136,1])\n",
    "y_ = tf.placeholder(tf.float32, shape=[None, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10880,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weight_variable(shape):\n",
    "  initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "  return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "  initial = tf.constant(0.1, shape=shape)\n",
    "  return tf.Variable(initial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### helper functions to build Conv and MaxPool layers\n",
    "\n",
    "def conv2d(x, W):\n",
    "  return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "def max_pool(x,psize):\n",
    "  return tf.nn.max_pool(x, ksize=[1, psize, psize, 1],\n",
    "                        strides=[1, psize, psize, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### weights and biases for the first Conv layer; 5x5 filter and 32 feat.\n",
    "W_conv1 = weight_variable([7, 7, 1, 32])\n",
    "b_conv1 = bias_variable([32])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### build first Conv and MaxPool layers\n",
    "h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\n",
    "h_pool1 = max_pool(h_conv1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(40), Dimension(68), Dimension(32)])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h_pool1.get_shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### stack a second Conv + MaxPool layer; again with 32 feat.\n",
    "W_conv2 = weight_variable([5, 5, 32, 32])\n",
    "b_conv2 = bias_variable([32])\n",
    "\n",
    "h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "h_pool2 = max_pool(h_conv2,2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(20), Dimension(34), Dimension(32)])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h_pool2.get_shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### stack a third Conv + MaxPool layer; this time 64 feat.\n",
    "W_conv3 = weight_variable([5, 5, 32, 64])\n",
    "b_conv3 = bias_variable([64])\n",
    "\n",
    "h_conv3 = tf.nn.relu(conv2d(h_pool2, W_conv3) + b_conv3)\n",
    "h_pool3 = max_pool(h_conv3,2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(10), Dimension(17), Dimension(64)])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h_pool3.get_shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### add fully-connected layer\n",
    "\n",
    "W_fc1 = weight_variable([10 * 17 * 64, 1024])\n",
    "b_fc1 = bias_variable([1024])\n",
    "\n",
    "h_pool3_flat = tf.reshape(h_pool3, [-1, 10*17*64])\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_pool3_flat, W_fc1) + b_fc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### dropout\n",
    "\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### output layer!\n",
    "W_fc2 = weight_variable([1024, 2])\n",
    "b_fc2 = bias_variable([2])\n",
    "\n",
    "y_conv=(tf.matmul(h_fc1_drop, W_fc2) + b_fc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### use least squares cost function\n",
    "cost_fn = tf.reduce_mean(tf.square(y_conv - y_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(cost_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sess' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-7ededded3c67>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialize_all_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0msaver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSaver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sess' is not defined"
     ]
    }
   ],
   "source": [
    "sess.run(tf.initialize_all_variables())\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "accuracy =  tf.reduce_mean(tf.square(y_conv - y_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMS error on training batch 0 : 70134.3\n",
      "RMS error on training batch 10 : 2706.78\n",
      "RMS error on training batch 20 : 2768.83\n",
      "RMS error on training batch 30 : 2814.41\n",
      "RMS error on training batch 40 : 2676.06\n",
      "RMS error on training batch 50 : 3271.0\n",
      "RMS error on training batch 60 : 2338.64\n",
      "RMS error on training batch 70 : 1752.29\n",
      "RMS error on training batch 80 : 1883.41\n",
      "RMS error on training batch 90 : 1582.06\n",
      "RMS error on training batch 100 : 1183.68\n",
      "RMS error on training batch 110 : 1355.92\n",
      "RMS error on training batch 120 : 1368.09\n",
      "RMS error on training batch 130 : 1496.86\n",
      "RMS error on training batch 140 : 1900.79\n",
      "RMS error on training batch 150 : 1291.38\n",
      "RMS error on training batch 160 : 1497.03\n",
      "RMS error on training batch 170 : 2045.68\n",
      "RMS error on training batch 180 : 972.466\n",
      "RMS error on training batch 190 : 1489.89\n",
      "RMS error on training batch 200 : 821.175\n",
      "RMS error on training batch 210 : 1371.78\n",
      "RMS error on training batch 220 : 1250.38\n",
      "RMS error on training batch 230 : 853.41\n",
      "RMS error on training batch 240 : 1386.72\n",
      "RMS error on training batch 250 : 679.082\n",
      "RMS error on training batch 260 : 1388.96\n",
      "RMS error on training batch 270 : 825.276\n",
      "RMS error on training batch 280 : 848.239\n",
      "RMS error on training batch 290 : 1031.57\n",
      "RMS error on training batch 300 : 1475.51\n",
      "RMS error on training batch 310 : 670.875\n",
      "RMS error on training batch 320 : 914.889\n",
      "RMS error on training batch 330 : 668.355\n",
      "RMS error on training batch 340 : 707.594\n",
      "RMS error on training batch 350 : 631.997\n",
      "RMS error on training batch 360 : 569.64\n",
      "RMS error on training batch 370 : 606.496\n",
      "RMS error on training batch 380 : 1125.46\n",
      "RMS error on training batch 390 : 1141.97\n",
      "RMS error on training batch 400 : 675.182\n",
      "RMS error on training batch 410 : 461.383\n",
      "RMS error on training batch 420 : 561.66\n",
      "RMS error on training batch 430 : 874.579\n",
      "RMS error on training batch 440 : 721.223\n",
      "RMS error on training batch 450 : 891.213\n",
      "RMS error on training batch 460 : 614.126\n",
      "RMS error on training batch 470 : 264.785\n",
      "RMS error on training batch 480 : 654.582\n",
      "RMS error on training batch 490 : 624.389\n",
      "RMS error on training batch 500 : 616.749\n",
      "RMS error on training batch 510 : 679.443\n",
      "RMS error on training batch 520 : 559.51\n",
      "RMS error on training batch 530 : 484.388\n",
      "RMS error on training batch 540 : 687.258\n",
      "RMS error on training batch 550 : 675.435\n",
      "RMS error on training batch 560 : 794.894\n",
      "RMS error on training batch 570 : 422.427\n",
      "RMS error on training batch 580 : 808.281\n",
      "RMS error on training batch 590 : 547.171\n",
      "RMS error on training batch 600 : 540.003\n",
      "RMS error on training batch 610 : 580.399\n",
      "RMS error on training batch 620 : 562.683\n",
      "RMS error on training batch 630 : 498.417\n",
      "RMS error on training batch 640 : 403.422\n",
      "RMS error on training batch 650 : 377.95\n",
      "RMS error on training batch 660 : 573.841\n",
      "RMS error on training batch 670 : 476.043\n",
      "RMS error on training batch 680 : 361.345\n",
      "RMS error on training batch 690 : 574.707\n",
      "RMS error on training batch 700 : 433.062\n",
      "RMS error on training batch 710 : 538.532\n",
      "RMS error on training batch 720 : 376.03\n",
      "RMS error on training batch 730 : 344.676\n",
      "RMS error on training batch 740 : 275.748\n",
      "RMS error on training batch 750 : 421.742\n",
      "RMS error on training batch 760 : 409.464\n",
      "RMS error on training batch 770 : 386.363\n",
      "RMS error on training batch 780 : 372.272\n",
      "RMS error on training batch 790 : 442.907\n",
      "RMS error on training batch 800 : 388.526\n",
      "RMS error on training batch 810 : 318.285\n",
      "RMS error on training batch 820 : 300.601\n",
      "RMS error on training batch 830 : 442.873\n",
      "RMS error on training batch 840 : 382.337\n",
      "RMS error on training batch 850 : 409.193\n",
      "RMS error on training batch 860 : 346.318\n",
      "RMS error on training batch 870 : 399.764\n",
      "RMS error on training batch 880 : 422.221\n",
      "RMS error on training batch 890 : 346.92\n",
      "RMS error on training batch 900 : 613.042\n",
      "RMS error on training batch 910 : 473.441\n",
      "RMS error on training batch 920 : 190.266\n",
      "RMS error on training batch 930 : 210.443\n",
      "RMS error on training batch 940 : 333.414\n",
      "RMS error on training batch 950 : 321.401\n",
      "RMS error on training batch 960 : 289.191\n",
      "RMS error on training batch 970 : 297.167\n",
      "RMS error on training batch 980 : 313.514\n",
      "RMS error on training batch 990 : 333.93\n",
      "RMS error on training batch 1000 : 304.488\n",
      "RMS error on training batch 1010 : 276.469\n",
      "RMS error on training batch 1020 : 284.76\n",
      "RMS error on training batch 1030 : 214.784\n",
      "RMS error on training batch 1040 : 269.621\n",
      "RMS error on training batch 1050 : 292.607\n",
      "RMS error on training batch 1060 : 442.643\n",
      "RMS error on training batch 1070 : 266.197\n",
      "RMS error on training batch 1080 : 545.928\n",
      "RMS error on training batch 1090 : 243.662\n",
      "RMS error on training batch 1100 : 305.808\n",
      "RMS error on training batch 1110 : 333.269\n",
      "RMS error on training batch 1120 : 260.34\n",
      "RMS error on training batch 1130 : 210.148\n",
      "RMS error on training batch 1140 : 211.594\n",
      "RMS error on training batch 1150 : 269.454\n",
      "RMS error on training batch 1160 : 267.829\n",
      "RMS error on training batch 1170 : 554.492\n",
      "RMS error on training batch 1180 : 232.969\n",
      "RMS error on training batch 1190 : 201.049\n",
      "RMS error on training batch 1200 : 402.579\n",
      "RMS error on training batch 1210 : 238.963\n",
      "RMS error on training batch 1220 : 380.662\n",
      "RMS error on training batch 1230 : 250.816\n",
      "RMS error on training batch 1240 : 186.037\n",
      "RMS error on training batch 1250 : 276.627\n",
      "RMS error on training batch 1260 : 214.461\n",
      "RMS error on training batch 1270 : 260.251\n",
      "RMS error on training batch 1280 : 254.74\n",
      "RMS error on training batch 1290 : 186.067\n",
      "RMS error on training batch 1300 : 301.987\n",
      "RMS error on training batch 1310 : 344.457\n",
      "RMS error on training batch 1320 : 313.158\n",
      "RMS error on training batch 1330 : 199.804\n",
      "RMS error on training batch 1340 : 290.351\n",
      "RMS error on training batch 1350 : 236.97\n",
      "RMS error on training batch 1360 : 379.356\n",
      "RMS error on training batch 1370 : 320.743\n",
      "RMS error on training batch 1380 : 165.668\n",
      "RMS error on training batch 1390 : 421.414\n",
      "RMS error on training batch 1400 : 247.955\n",
      "RMS error on training batch 1410 : 282.667\n",
      "RMS error on training batch 1420 : 151.318\n",
      "RMS error on training batch 1430 : 213.116\n",
      "RMS error on training batch 1440 : 325.121\n",
      "RMS error on training batch 1450 : 306.471\n",
      "RMS error on training batch 1460 : 212.576\n",
      "RMS error on training batch 1470 : 201.563\n",
      "RMS error on training batch 1480 : 342.393\n",
      "RMS error on training batch 1490 : 471.837\n",
      "RMS error on training batch 1500 : 183.046\n",
      "RMS error on training batch 1510 : 218.644\n",
      "RMS error on training batch 1520 : 184.003\n",
      "RMS error on training batch 1530 : 214.312\n",
      "RMS error on training batch 1540 : 294.766\n",
      "RMS error on training batch 1550 : 282.087\n",
      "RMS error on training batch 1560 : 244.831\n",
      "RMS error on training batch 1570 : 181.835\n",
      "RMS error on training batch 1580 : 162.946\n",
      "RMS error on training batch 1590 : 233.429\n",
      "RMS error on training batch 1600 : 187.877\n",
      "RMS error on training batch 1610 : 180.573\n",
      "RMS error on training batch 1620 : 259.501\n",
      "RMS error on training batch 1630 : 191.109\n",
      "RMS error on training batch 1640 : 163.046\n",
      "RMS error on training batch 1650 : 222.652\n",
      "RMS error on training batch 1660 : 181.785\n",
      "RMS error on training batch 1670 : 183.312\n",
      "RMS error on training batch 1680 : 445.662\n",
      "RMS error on training batch 1690 : 160.765\n",
      "RMS error on training batch 1700 : 187.624\n",
      "RMS error on training batch 1710 : 136.872\n",
      "RMS error on training batch 1720 : 113.116\n",
      "RMS error on training batch 1730 : 117.326\n",
      "RMS error on training batch 1740 : 143.814\n",
      "RMS error on training batch 1750 : 173.86\n",
      "RMS error on training batch 1760 : 287.843\n",
      "RMS error on training batch 1770 : 187.98\n",
      "RMS error on training batch 1780 : 114.756\n",
      "RMS error on training batch 1790 : 153.184\n",
      "RMS error on training batch 1800 : 163.207\n",
      "RMS error on training batch 1810 : 418.941\n",
      "RMS error on training batch 1820 : 226.457\n",
      "RMS error on training batch 1830 : 278.556\n",
      "RMS error on training batch 1840 : 131.652\n",
      "RMS error on training batch 1850 : 131.273\n",
      "RMS error on training batch 1860 : 158.546\n",
      "RMS error on training batch 1870 : 204.297\n",
      "RMS error on training batch 1880 : 310.443\n",
      "RMS error on training batch 1890 : 238.726\n",
      "RMS error on training batch 1900 : 175.499\n",
      "RMS error on training batch 1910 : 160.188\n",
      "RMS error on training batch 1920 : 114.717\n",
      "RMS error on training batch 1930 : 143.742\n",
      "RMS error on training batch 1940 : 96.7242\n",
      "RMS error on training batch 1950 : 104.261\n",
      "RMS error on training batch 1960 : 115.878\n",
      "RMS error on training batch 1970 : 131.584\n",
      "RMS error on training batch 1980 : 210.507\n",
      "RMS error on training batch 1990 : 155.72\n",
      "RMS error on training batch 2000 : 89.0141\n",
      "RMS error on training batch 2010 : 196.07\n",
      "RMS error on training batch 2020 : 124.811\n",
      "RMS error on training batch 2030 : 140.375\n",
      "RMS error on training batch 2040 : 105.279\n",
      "RMS error on training batch 2050 : 173.279\n",
      "RMS error on training batch 2060 : 133.981\n",
      "RMS error on training batch 2070 : 162.227\n",
      "RMS error on training batch 2080 : 160.393\n",
      "RMS error on training batch 2090 : 99.9527\n",
      "RMS error on training batch 2100 : 143.625\n",
      "RMS error on training batch 2110 : 183.308\n",
      "RMS error on training batch 2120 : 104.128\n",
      "RMS error on training batch 2130 : 158.039\n",
      "RMS error on training batch 2140 : 148.447\n",
      "RMS error on training batch 2150 : 112.849\n",
      "RMS error on training batch 2160 : 180.183\n",
      "RMS error on training batch 2170 : 290.386\n",
      "RMS error on training batch 2180 : 212.702\n",
      "RMS error on training batch 2190 : 208.796\n",
      "RMS error on training batch 2200 : 97.6817\n",
      "RMS error on training batch 2210 : 106.866\n",
      "RMS error on training batch 2220 : 122.824\n",
      "RMS error on training batch 2230 : 109.951\n",
      "RMS error on training batch 2240 : 163.879\n",
      "RMS error on training batch 2250 : 107.285\n",
      "RMS error on training batch 2260 : 104.342\n",
      "RMS error on training batch 2270 : 239.494\n",
      "RMS error on training batch 2280 : 100.757\n",
      "RMS error on training batch 2290 : 122.762\n",
      "RMS error on training batch 2300 : 114.388\n",
      "RMS error on training batch 2310 : 164.592\n",
      "RMS error on training batch 2320 : 117.537\n",
      "RMS error on training batch 2330 : 303.91\n",
      "RMS error on training batch 2340 : 232.737\n",
      "RMS error on training batch 2350 : 122.47\n",
      "RMS error on training batch 2360 : 120.15\n",
      "RMS error on training batch 2370 : 176.292\n",
      "RMS error on training batch 2380 : 106.098\n",
      "RMS error on training batch 2390 : 90.0487\n",
      "RMS error on training batch 2400 : 227.433\n",
      "RMS error on training batch 2410 : 125.852\n",
      "RMS error on training batch 2420 : 117.856\n",
      "RMS error on training batch 2430 : 117.18\n",
      "RMS error on training batch 2440 : 256.236\n",
      "RMS error on training batch 2450 : 141.339\n",
      "RMS error on training batch 2460 : 97.9367\n",
      "RMS error on training batch 2470 : 108.096\n",
      "RMS error on training batch 2480 : 99.9982\n",
      "RMS error on training batch 2490 : 85.1038\n",
      "RMS error on training batch 2500 : 127.352\n",
      "RMS error on training batch 2510 : 111.8\n",
      "RMS error on training batch 2520 : 175.382\n",
      "RMS error on training batch 2530 : 79.0507\n",
      "RMS error on training batch 2540 : 123.745\n",
      "RMS error on training batch 2550 : 117.636\n",
      "RMS error on training batch 2560 : 120.295\n",
      "RMS error on training batch 2570 : 114.245\n",
      "RMS error on training batch 2580 : 145.55\n",
      "RMS error on training batch 2590 : 136.029\n",
      "RMS error on training batch 2600 : 120.579\n",
      "RMS error on training batch 2610 : 104.452\n",
      "RMS error on training batch 2620 : 133.175\n",
      "RMS error on training batch 2630 : 98.0329\n",
      "RMS error on training batch 2640 : 117.99\n",
      "RMS error on training batch 2650 : 104.569\n",
      "RMS error on training batch 2660 : 92.2282\n",
      "RMS error on training batch 2670 : 79.0715\n",
      "RMS error on training batch 2680 : 97.864\n",
      "RMS error on training batch 2690 : 107.795\n",
      "RMS error on training batch 2700 : 65.5411\n",
      "RMS error on training batch 2710 : 115.617\n",
      "RMS error on training batch 2720 : 118.008\n",
      "RMS error on training batch 2730 : 99.0062\n",
      "RMS error on training batch 2740 : 214.786\n",
      "RMS error on training batch 2750 : 147.642\n",
      "RMS error on training batch 2760 : 149.925\n",
      "RMS error on training batch 2770 : 150.042\n",
      "RMS error on training batch 2780 : 94.8181\n",
      "RMS error on training batch 2790 : 61.1847\n",
      "RMS error on training batch 2800 : 135.166\n",
      "RMS error on training batch 2810 : 104.299\n",
      "RMS error on training batch 2820 : 110.323\n",
      "RMS error on training batch 2830 : 109.3\n",
      "RMS error on training batch 2840 : 84.8663\n",
      "RMS error on training batch 2850 : 142.097\n",
      "RMS error on training batch 2860 : 74.8792\n",
      "RMS error on training batch 2870 : 137.018\n",
      "RMS error on training batch 2880 : 171.607\n",
      "RMS error on training batch 2890 : 305.044\n",
      "RMS error on training batch 2900 : 132.644\n",
      "RMS error on training batch 2910 : 59.9957\n",
      "RMS error on training batch 2920 : 137.288\n",
      "RMS error on training batch 2930 : 97.1141\n",
      "RMS error on training batch 2940 : 101.986\n",
      "RMS error on training batch 2950 : 79.2941\n",
      "RMS error on training batch 2960 : 91.6471\n",
      "RMS error on training batch 2970 : 74.421\n",
      "RMS error on training batch 2980 : 88.3046\n",
      "RMS error on training batch 2990 : 79.8983\n",
      "RMS error on training batch 3000 : 64.949\n",
      "RMS error on training batch 3010 : 77.8588\n",
      "RMS error on training batch 3020 : 48.4471\n",
      "RMS error on training batch 3030 : 65.734\n",
      "RMS error on training batch 3040 : 137.95\n",
      "RMS error on training batch 3050 : 77.7399\n",
      "RMS error on training batch 3060 : 57.0402\n",
      "RMS error on training batch 3070 : 122.348\n",
      "RMS error on training batch 3080 : 91.3769\n",
      "RMS error on training batch 3090 : 81.4919\n",
      "RMS error on training batch 3100 : 125.827\n",
      "RMS error on training batch 3110 : 116.707\n",
      "RMS error on training batch 3120 : 90.7396\n",
      "RMS error on training batch 3130 : 61.6472\n",
      "RMS error on training batch 3140 : 71.7067\n",
      "RMS error on training batch 3150 : 105.083\n",
      "RMS error on training batch 3160 : 69.5585\n",
      "RMS error on training batch 3170 : 107.117\n",
      "RMS error on training batch 3180 : 124.035\n",
      "RMS error on training batch 3190 : 66.9387\n",
      "RMS error on training batch 3200 : 131.011\n",
      "RMS error on training batch 3210 : 117.512\n",
      "RMS error on training batch 3220 : 98.8846\n",
      "RMS error on training batch 3230 : 148.98\n",
      "RMS error on training batch 3240 : 142.292\n",
      "RMS error on training batch 3250 : 192.688\n",
      "RMS error on training batch 3260 : 89.133\n",
      "RMS error on training batch 3270 : 87.6085\n",
      "RMS error on training batch 3280 : 87.9537\n",
      "RMS error on training batch 3290 : 82.4428\n",
      "RMS error on training batch 3300 : 126.654\n",
      "RMS error on training batch 3310 : 82.7338\n",
      "RMS error on training batch 3320 : 112.89\n",
      "RMS error on training batch 3330 : 79.8147\n",
      "RMS error on training batch 3340 : 113.878\n",
      "RMS error on training batch 3350 : 105.501\n",
      "RMS error on training batch 3360 : 130.183\n",
      "RMS error on training batch 3370 : 81.7513\n",
      "RMS error on training batch 3380 : 73.4688\n",
      "RMS error on training batch 3390 : 82.7612\n",
      "RMS error on training batch 3400 : 141.014\n",
      "RMS error on training batch 3410 : 57.7518\n",
      "RMS error on training batch 3420 : 104.009\n",
      "RMS error on training batch 3430 : 124.146\n",
      "RMS error on training batch 3440 : 55.1436\n",
      "RMS error on training batch 3450 : 64.2566\n",
      "RMS error on training batch 3460 : 65.6004\n",
      "RMS error on training batch 3470 : 158.032\n",
      "RMS error on training batch 3480 : 93.6854\n",
      "RMS error on training batch 3490 : 50.0699\n",
      "RMS error on training batch 3500 : 171.727\n",
      "RMS error on training batch 3510 : 258.635\n",
      "RMS error on training batch 3520 : 126.484\n",
      "RMS error on training batch 3530 : 179.759\n",
      "RMS error on training batch 3540 : 70.0926\n",
      "RMS error on training batch 3550 : 120.602\n",
      "RMS error on training batch 3560 : 140.28\n",
      "RMS error on training batch 3570 : 61.6729\n",
      "RMS error on training batch 3580 : 173.899\n",
      "RMS error on training batch 3590 : 110.77\n",
      "RMS error on training batch 3600 : 89.6049\n",
      "RMS error on training batch 3610 : 64.2342\n",
      "RMS error on training batch 3620 : 78.4484\n",
      "RMS error on training batch 3630 : 61.7896\n",
      "RMS error on training batch 3640 : 96.9567\n",
      "RMS error on training batch 3650 : 45.1191\n",
      "RMS error on training batch 3660 : 77.8952\n",
      "RMS error on training batch 3670 : 47.2969\n",
      "RMS error on training batch 3680 : 79.7982\n",
      "RMS error on training batch 3690 : 173.609\n",
      "RMS error on training batch 3700 : 79.2061\n",
      "RMS error on training batch 3710 : 115.632\n",
      "RMS error on training batch 3720 : 99.1922\n",
      "RMS error on training batch 3730 : 100.645\n",
      "RMS error on training batch 3740 : 56.2722\n",
      "RMS error on training batch 3750 : 57.0645\n",
      "RMS error on training batch 3760 : 82.7723\n",
      "RMS error on training batch 3770 : 85.3129\n",
      "RMS error on training batch 3780 : 112.286\n",
      "RMS error on training batch 3790 : 52.7035\n",
      "RMS error on training batch 3800 : 77.421\n",
      "RMS error on training batch 3810 : 69.5461\n",
      "RMS error on training batch 3820 : 79.7802\n",
      "RMS error on training batch 3830 : 160.128\n",
      "RMS error on training batch 3840 : 139.128\n",
      "RMS error on training batch 3850 : 86.258\n",
      "RMS error on training batch 3860 : 91.5824\n",
      "RMS error on training batch 3870 : 98.2458\n",
      "RMS error on training batch 3880 : 52.1963\n",
      "RMS error on training batch 3890 : 65.4413\n",
      "RMS error on training batch 3900 : 82.6894\n",
      "RMS error on training batch 3910 : 90.87\n",
      "RMS error on training batch 3920 : 89.1737\n",
      "RMS error on training batch 3930 : 30.2005\n",
      "RMS error on training batch 3940 : 72.4461\n",
      "RMS error on training batch 3950 : 50.4656\n",
      "RMS error on training batch 3960 : 95.2854\n",
      "RMS error on training batch 3970 : 62.4991\n",
      "RMS error on training batch 3980 : 147.73\n",
      "RMS error on training batch 3990 : 64.3873\n",
      "RMS error on training batch 4000 : 45.7939\n",
      "RMS error on training batch 4010 : 70.7052\n",
      "RMS error on training batch 4020 : 67.756\n",
      "RMS error on training batch 4030 : 56.6193\n",
      "RMS error on training batch 4040 : 81.6107\n",
      "RMS error on training batch 4050 : 219.139\n",
      "RMS error on training batch 4060 : 162.977\n",
      "RMS error on training batch 4070 : 86.1513\n",
      "RMS error on training batch 4080 : 89.2381\n",
      "RMS error on training batch 4090 : 74.322\n",
      "RMS error on training batch 4100 : 72.9614\n",
      "RMS error on training batch 4110 : 75.8064\n",
      "RMS error on training batch 4120 : 132.063\n",
      "RMS error on training batch 4130 : 201.402\n",
      "RMS error on training batch 4140 : 64.3562\n",
      "RMS error on training batch 4150 : 66.2357\n",
      "RMS error on training batch 4160 : 65.413\n",
      "RMS error on training batch 4170 : 49.0425\n",
      "RMS error on training batch 4180 : 82.6427\n",
      "RMS error on training batch 4190 : 58.7267\n",
      "RMS error on training batch 4200 : 71.1212\n",
      "RMS error on training batch 4210 : 106.236\n",
      "RMS error on training batch 4220 : 96.493\n",
      "RMS error on training batch 4230 : 49.7553\n",
      "RMS error on training batch 4240 : 65.202\n",
      "RMS error on training batch 4250 : 51.5617\n",
      "RMS error on training batch 4260 : 49.1952\n",
      "RMS error on training batch 4270 : 64.3206\n",
      "RMS error on training batch 4280 : 82.069\n",
      "RMS error on training batch 4290 : 66.2638\n",
      "RMS error on training batch 4300 : 117.302\n",
      "RMS error on training batch 4310 : 82.9668\n",
      "RMS error on training batch 4320 : 160.435\n",
      "RMS error on training batch 4330 : 103.931\n",
      "RMS error on training batch 4340 : 62.4006\n",
      "RMS error on training batch 4350 : 69.6498\n",
      "RMS error on training batch 4360 : 67.7745\n",
      "RMS error on training batch 4370 : 50.692\n",
      "RMS error on training batch 4380 : 109.23\n",
      "RMS error on training batch 4390 : 70.9246\n",
      "RMS error on training batch 4400 : 82.2596\n",
      "RMS error on training batch 4410 : 172.234\n",
      "RMS error on training batch 4420 : 67.6737\n",
      "RMS error on training batch 4430 : 42.5597\n",
      "RMS error on training batch 4440 : 57.9638\n",
      "RMS error on training batch 4450 : 97.7779\n",
      "RMS error on training batch 4460 : 59.0088\n",
      "RMS error on training batch 4470 : 65.6926\n",
      "RMS error on training batch 4480 : 70.845\n",
      "RMS error on training batch 4490 : 67.9644\n",
      "RMS error on training batch 4500 : 47.2918\n",
      "RMS error on training batch 4510 : 95.4813\n",
      "RMS error on training batch 4520 : 72.6044\n",
      "RMS error on training batch 4530 : 61.4008\n",
      "RMS error on training batch 4540 : 45.9357\n",
      "RMS error on training batch 4550 : 76.0383\n",
      "RMS error on training batch 4560 : 126.297\n",
      "RMS error on training batch 4570 : 74.3355\n",
      "RMS error on training batch 4580 : 174.223\n",
      "RMS error on training batch 4590 : 69.2721\n",
      "RMS error on training batch 4600 : 137.431\n",
      "RMS error on training batch 4610 : 131.072\n",
      "RMS error on training batch 4620 : 113.194\n",
      "RMS error on training batch 4630 : 89.0891\n",
      "RMS error on training batch 4640 : 65.3771\n",
      "RMS error on training batch 4650 : 115.2\n",
      "RMS error on training batch 4660 : 110.877\n",
      "RMS error on training batch 4670 : 61.8823\n",
      "RMS error on training batch 4680 : 67.3182\n",
      "RMS error on training batch 4690 : 56.1866\n",
      "RMS error on training batch 4700 : 69.5638\n",
      "RMS error on training batch 4710 : 89.9789\n",
      "RMS error on training batch 4720 : 64.1815\n",
      "RMS error on training batch 4730 : 44.1764\n",
      "RMS error on training batch 4740 : 44.8187\n",
      "RMS error on training batch 4750 : 52.4939\n",
      "RMS error on training batch 4760 : 41.8648\n",
      "RMS error on training batch 4770 : 37.3436\n",
      "RMS error on training batch 4780 : 45.787\n",
      "RMS error on training batch 4790 : 47.3645\n",
      "RMS error on training batch 4800 : 65.489\n",
      "RMS error on training batch 4810 : 101.027\n",
      "RMS error on training batch 4820 : 64.4238\n",
      "RMS error on training batch 4830 : 31.3964\n",
      "RMS error on training batch 4840 : 62.3693\n",
      "RMS error on training batch 4850 : 55.2245\n",
      "RMS error on training batch 4860 : 59.7235\n",
      "RMS error on training batch 4870 : 77.1653\n",
      "RMS error on training batch 4880 : 66.2241\n",
      "RMS error on training batch 4890 : 45.926\n",
      "RMS error on training batch 4900 : 114.997\n",
      "RMS error on training batch 4910 : 45.9405\n",
      "RMS error on training batch 4920 : 77.0897\n",
      "RMS error on training batch 4930 : 74.4229\n",
      "RMS error on training batch 4940 : 78.7436\n",
      "RMS error on training batch 4950 : 41.1348\n",
      "RMS error on training batch 4960 : 62.2103\n",
      "RMS error on training batch 4970 : 22.8847\n",
      "RMS error on training batch 4980 : 37.6477\n",
      "RMS error on training batch 4990 : 99.305\n",
      "RMS error on training batch 5000 : 66.3503\n",
      "RMS error on training batch 5010 : 45.7946\n",
      "RMS error on training batch 5020 : 38.3787\n",
      "RMS error on training batch 5030 : 61.24\n",
      "RMS error on training batch 5040 : 107.948\n",
      "RMS error on training batch 5050 : 83.9583\n",
      "RMS error on training batch 5060 : 83.7661\n",
      "RMS error on training batch 5070 : 38.3407\n",
      "RMS error on training batch 5080 : 76.3509\n",
      "RMS error on training batch 5090 : 74.7209\n",
      "RMS error on training batch 5100 : 32.9453\n",
      "RMS error on training batch 5110 : 32.2652\n",
      "RMS error on training batch 5120 : 42.8795\n",
      "RMS error on training batch 5130 : 41.018\n",
      "RMS error on training batch 5140 : 56.0261\n",
      "RMS error on training batch 5150 : 116.296\n",
      "RMS error on training batch 5160 : 70.984\n",
      "RMS error on training batch 5170 : 48.0803\n",
      "RMS error on training batch 5180 : 35.9451\n",
      "RMS error on training batch 5190 : 64.5265\n",
      "RMS error on training batch 5200 : 65.9356\n",
      "RMS error on training batch 5210 : 87.4724\n",
      "RMS error on training batch 5220 : 40.759\n",
      "RMS error on training batch 5230 : 85.7387\n",
      "RMS error on training batch 5240 : 75.4713\n",
      "RMS error on training batch 5250 : 70.4332\n",
      "RMS error on training batch 5260 : 41.4702\n",
      "RMS error on training batch 5270 : 130.418\n",
      "RMS error on training batch 5280 : 57.9074\n",
      "RMS error on training batch 5290 : 42.2435\n",
      "RMS error on training batch 5300 : 64.2268\n",
      "RMS error on training batch 5310 : 44.687\n",
      "RMS error on training batch 5320 : 47.7476\n",
      "RMS error on training batch 5330 : 100.713\n",
      "RMS error on training batch 5340 : 60.5444\n",
      "RMS error on training batch 5350 : 79.4012\n",
      "RMS error on training batch 5360 : 34.4325\n",
      "RMS error on training batch 5370 : 31.7083\n",
      "RMS error on training batch 5380 : 49.186\n",
      "RMS error on training batch 5390 : 67.8762\n",
      "RMS error on training batch 5400 : 40.0018\n",
      "RMS error on training batch 5410 : 56.4145\n",
      "RMS error on training batch 5420 : 35.0878\n",
      "RMS error on training batch 5430 : 51.5841\n",
      "RMS error on training batch 5440 : 66.4361\n",
      "RMS error on training batch 5450 : 84.7033\n",
      "RMS error on training batch 5460 : 65.9192\n",
      "RMS error on training batch 5470 : 73.9514\n",
      "RMS error on training batch 5480 : 54.5353\n",
      "RMS error on training batch 5490 : 69.8044\n",
      "RMS error on training batch 5500 : 52.5606\n",
      "RMS error on training batch 5510 : 30.6328\n",
      "RMS error on training batch 5520 : 34.9432\n",
      "RMS error on training batch 5530 : 25.5967\n",
      "RMS error on training batch 5540 : 46.3563\n",
      "RMS error on training batch 5550 : 54.5601\n",
      "RMS error on training batch 5560 : 101.358\n",
      "RMS error on training batch 5570 : 76.1521\n",
      "RMS error on training batch 5580 : 62.7299\n",
      "RMS error on training batch 5590 : 26.189\n",
      "RMS error on training batch 5600 : 71.1671\n",
      "RMS error on training batch 5610 : 67.3729\n",
      "RMS error on training batch 5620 : 56.4143\n",
      "RMS error on training batch 5630 : 74.8426\n",
      "RMS error on training batch 5640 : 89.5189\n",
      "RMS error on training batch 5650 : 34.8961\n",
      "RMS error on training batch 5660 : 71.9707\n",
      "RMS error on training batch 5670 : 50.6734\n",
      "RMS error on training batch 5680 : 54.129\n",
      "RMS error on training batch 5690 : 40.9549\n",
      "RMS error on training batch 5700 : 55.095\n",
      "RMS error on training batch 5710 : 41.6141\n",
      "RMS error on training batch 5720 : 49.0809\n",
      "RMS error on training batch 5730 : 62.41\n",
      "RMS error on training batch 5740 : 51.9818\n",
      "RMS error on training batch 5750 : 48.3987\n",
      "RMS error on training batch 5760 : 44.4784\n",
      "RMS error on training batch 5770 : 44.3281\n",
      "RMS error on training batch 5780 : 42.8267\n",
      "RMS error on training batch 5790 : 29.1025\n",
      "RMS error on training batch 5800 : 21.2733\n",
      "RMS error on training batch 5810 : 70.5586\n",
      "RMS error on training batch 5820 : 36.0487\n",
      "RMS error on training batch 5830 : 42.5631\n",
      "RMS error on training batch 5840 : 59.8929\n",
      "RMS error on training batch 5850 : 76.3723\n",
      "RMS error on training batch 5860 : 81.1612\n",
      "RMS error on training batch 5870 : 47.0704\n",
      "RMS error on training batch 5880 : 52.5717\n",
      "RMS error on training batch 5890 : 55.5243\n",
      "RMS error on training batch 5900 : 72.2636\n",
      "RMS error on training batch 5910 : 126.119\n",
      "RMS error on training batch 5920 : 40.9756\n",
      "RMS error on training batch 5930 : 65.9267\n",
      "RMS error on training batch 5940 : 47.262\n",
      "RMS error on training batch 5950 : 33.2813\n",
      "RMS error on training batch 5960 : 72.483\n",
      "RMS error on training batch 5970 : 89.0205\n",
      "RMS error on training batch 5980 : 38.7365\n",
      "RMS error on training batch 5990 : 44.6563\n",
      "RMS error on training batch 6000 : 38.148\n",
      "RMS error on training batch 6010 : 47.3854\n",
      "RMS error on training batch 6020 : 38.8243\n",
      "RMS error on training batch 6030 : 52.5626\n",
      "RMS error on training batch 6040 : 64.9974\n",
      "RMS error on training batch 6050 : 105.314\n",
      "RMS error on training batch 6060 : 46.288\n",
      "RMS error on training batch 6070 : 67.034\n",
      "RMS error on training batch 6080 : 68.6809\n",
      "RMS error on training batch 6090 : 37.9716\n",
      "RMS error on training batch 6100 : 55.3149\n",
      "RMS error on training batch 6110 : 29.9838\n",
      "RMS error on training batch 6120 : 18.8944\n",
      "RMS error on training batch 6130 : 48.609\n",
      "RMS error on training batch 6140 : 40.5403\n",
      "RMS error on training batch 6150 : 69.7892\n",
      "RMS error on training batch 6160 : 65.5507\n",
      "RMS error on training batch 6170 : 56.7575\n",
      "RMS error on training batch 6180 : 46.5873\n",
      "RMS error on training batch 6190 : 83.5667\n",
      "RMS error on training batch 6200 : 49.749\n",
      "RMS error on training batch 6210 : 59.4295\n",
      "RMS error on training batch 6220 : 59.8779\n",
      "RMS error on training batch 6230 : 37.8979\n",
      "RMS error on training batch 6240 : 44.5317\n",
      "RMS error on training batch 6250 : 30.5559\n",
      "RMS error on training batch 6260 : 26.731\n",
      "RMS error on training batch 6270 : 53.8488\n",
      "RMS error on training batch 6280 : 57.3196\n",
      "RMS error on training batch 6290 : 33.7423\n",
      "RMS error on training batch 6300 : 30.1253\n",
      "RMS error on training batch 6310 : 68.422\n",
      "RMS error on training batch 6320 : 39.8772\n",
      "RMS error on training batch 6330 : 48.2113\n",
      "RMS error on training batch 6340 : 70.2842\n",
      "RMS error on training batch 6350 : 40.5226\n",
      "RMS error on training batch 6360 : 54.2988\n",
      "RMS error on training batch 6370 : 61.3298\n",
      "RMS error on training batch 6380 : 40.9965\n",
      "RMS error on training batch 6390 : 31.6399\n",
      "RMS error on training batch 6400 : 64.0451\n",
      "RMS error on training batch 6410 : 38.8346\n",
      "RMS error on training batch 6420 : 23.2594\n",
      "RMS error on training batch 6430 : 50.1442\n",
      "RMS error on training batch 6440 : 60.5234\n",
      "RMS error on training batch 6450 : 56.6557\n",
      "RMS error on training batch 6460 : 92.112\n",
      "RMS error on training batch 6470 : 47.3978\n",
      "RMS error on training batch 6480 : 80.3858\n",
      "RMS error on training batch 6490 : 41.1568\n",
      "RMS error on training batch 6500 : 37.9884\n",
      "RMS error on training batch 6510 : 45.1136\n",
      "RMS error on training batch 6520 : 41.216\n",
      "RMS error on training batch 6530 : 47.3118\n",
      "RMS error on training batch 6540 : 41.3021\n",
      "RMS error on training batch 6550 : 34.0902\n",
      "RMS error on training batch 6560 : 34.6734\n",
      "RMS error on training batch 6570 : 82.342\n",
      "RMS error on training batch 6580 : 41.9326\n",
      "RMS error on training batch 6590 : 35.9725\n",
      "RMS error on training batch 6600 : 67.4784\n",
      "RMS error on training batch 6610 : 28.1776\n",
      "RMS error on training batch 6620 : 29.5095\n",
      "RMS error on training batch 6630 : 43.7848\n",
      "RMS error on training batch 6640 : 44.9621\n",
      "RMS error on training batch 6650 : 38.4015\n",
      "RMS error on training batch 6660 : 28.5788\n",
      "RMS error on training batch 6670 : 33.1213\n",
      "RMS error on training batch 6680 : 58.5005\n",
      "RMS error on training batch 6690 : 29.8399\n",
      "RMS error on training batch 6700 : 34.589\n",
      "RMS error on training batch 6710 : 42.1962\n",
      "RMS error on training batch 6720 : 59.1992\n",
      "RMS error on training batch 6730 : 50.8918\n",
      "RMS error on training batch 6740 : 38.995\n",
      "RMS error on training batch 6750 : 60.6451\n",
      "RMS error on training batch 6760 : 32.683\n",
      "RMS error on training batch 6770 : 24.815\n",
      "RMS error on training batch 6780 : 101.021\n",
      "RMS error on training batch 6790 : 62.3495\n",
      "RMS error on training batch 6800 : 38.1708\n",
      "RMS error on training batch 6810 : 46.1557\n",
      "RMS error on training batch 6820 : 57.9943\n",
      "RMS error on training batch 6830 : 45.8445\n",
      "RMS error on training batch 6840 : 37.8642\n",
      "RMS error on training batch 6850 : 39.6684\n",
      "RMS error on training batch 6860 : 109.89\n",
      "RMS error on training batch 6870 : 85.7013\n",
      "RMS error on training batch 6880 : 20.6044\n",
      "RMS error on training batch 6890 : 45.7748\n",
      "RMS error on training batch 6900 : 49.3715\n",
      "RMS error on training batch 6910 : 36.5729\n",
      "RMS error on training batch 6920 : 46.0721\n",
      "RMS error on training batch 6930 : 64.0053\n",
      "RMS error on training batch 6940 : 39.7873\n",
      "RMS error on training batch 6950 : 30.3872\n",
      "RMS error on training batch 6960 : 42.7528\n",
      "RMS error on training batch 6970 : 69.2809\n",
      "RMS error on training batch 6980 : 40.1288\n",
      "RMS error on training batch 6990 : 25.0238\n",
      "RMS error on training batch 7000 : 24.3558\n",
      "RMS error on training batch 7010 : 64.0975\n",
      "RMS error on training batch 7020 : 27.3314\n",
      "RMS error on training batch 7030 : 40.9746\n",
      "RMS error on training batch 7040 : 43.1054\n",
      "RMS error on training batch 7050 : 27.8915\n",
      "RMS error on training batch 7060 : 59.2634\n",
      "RMS error on training batch 7070 : 58.5747\n",
      "RMS error on training batch 7080 : 32.4819\n",
      "RMS error on training batch 7090 : 86.5735\n",
      "RMS error on training batch 7100 : 103.403\n",
      "RMS error on training batch 7110 : 39.787\n",
      "RMS error on training batch 7120 : 60.6443\n",
      "RMS error on training batch 7130 : 54.2865\n",
      "RMS error on training batch 7140 : 43.7237\n",
      "RMS error on training batch 7150 : 43.7095\n",
      "RMS error on training batch 7160 : 29.5561\n",
      "RMS error on training batch 7170 : 23.7292\n",
      "RMS error on training batch 7180 : 48.778\n",
      "RMS error on training batch 7190 : 54.3736\n",
      "RMS error on training batch 7200 : 45.1522\n",
      "RMS error on training batch 7210 : 27.0866\n",
      "RMS error on training batch 7220 : 71.2808\n",
      "RMS error on training batch 7230 : 57.5086\n",
      "RMS error on training batch 7240 : 57.0781\n",
      "RMS error on training batch 7250 : 60.5845\n",
      "RMS error on training batch 7260 : 40.9088\n",
      "RMS error on training batch 7270 : 34.5678\n",
      "RMS error on training batch 7280 : 47.6837\n",
      "RMS error on training batch 7290 : 131.426\n",
      "RMS error on training batch 7300 : 41.5069\n",
      "RMS error on training batch 7310 : 39.7885\n",
      "RMS error on training batch 7320 : 66.0253\n",
      "RMS error on training batch 7330 : 66.3191\n",
      "RMS error on training batch 7340 : 46.1196\n",
      "RMS error on training batch 7350 : 55.6298\n",
      "RMS error on training batch 7360 : 44.9582\n",
      "RMS error on training batch 7370 : 34.5618\n",
      "RMS error on training batch 7380 : 40.1911\n",
      "RMS error on training batch 7390 : 45.1835\n",
      "RMS error on training batch 7400 : 35.5392\n",
      "RMS error on training batch 7410 : 26.504\n",
      "RMS error on training batch 7420 : 46.7472\n",
      "RMS error on training batch 7430 : 28.5707\n",
      "RMS error on training batch 7440 : 58.0967\n",
      "RMS error on training batch 7450 : 22.7714\n",
      "RMS error on training batch 7460 : 39.8977\n",
      "RMS error on training batch 7470 : 40.2458\n",
      "RMS error on training batch 7480 : 40.2742\n",
      "RMS error on training batch 7490 : 44.2619\n",
      "RMS error on training batch 7500 : 59.1425\n",
      "RMS error on training batch 7510 : 74.5708\n",
      "RMS error on training batch 7520 : 35.1219\n",
      "RMS error on training batch 7530 : 101.786\n",
      "RMS error on training batch 7540 : 38.4466\n",
      "RMS error on training batch 7550 : 64.1067\n",
      "RMS error on training batch 7560 : 43.8265\n",
      "RMS error on training batch 7570 : 48.0408\n",
      "RMS error on training batch 7580 : 75.1483\n",
      "RMS error on training batch 7590 : 37.2513\n",
      "RMS error on training batch 7600 : 30.7709\n",
      "RMS error on training batch 7610 : 27.2571\n",
      "RMS error on training batch 7620 : 46.4693\n",
      "RMS error on training batch 7630 : 38.6189\n",
      "RMS error on training batch 7640 : 39.8912\n",
      "RMS error on training batch 7650 : 90.8495\n",
      "RMS error on training batch 7660 : 71.3312\n",
      "RMS error on training batch 7670 : 63.7654\n",
      "RMS error on training batch 7680 : 33.383\n",
      "RMS error on training batch 7690 : 24.7473\n",
      "RMS error on training batch 7700 : 44.7208\n",
      "RMS error on training batch 7710 : 44.0056\n",
      "RMS error on training batch 7720 : 52.0378\n",
      "RMS error on training batch 7730 : 33.5519\n",
      "RMS error on training batch 7740 : 46.555\n",
      "RMS error on training batch 7750 : 31.4246\n",
      "RMS error on training batch 7760 : 48.5147\n",
      "RMS error on training batch 7770 : 31.5347\n",
      "RMS error on training batch 7780 : 49.9644\n",
      "RMS error on training batch 7790 : 33.1663\n",
      "RMS error on training batch 7800 : 22.1705\n",
      "RMS error on training batch 7810 : 27.622\n",
      "RMS error on training batch 7820 : 52.4485\n",
      "RMS error on training batch 7830 : 54.6175\n",
      "RMS error on training batch 7840 : 50.4771\n",
      "RMS error on training batch 7850 : 44.4514\n",
      "RMS error on training batch 7860 : 52.5857\n",
      "RMS error on training batch 7870 : 48.6966\n",
      "RMS error on training batch 7880 : 16.1676\n",
      "RMS error on training batch 7890 : 21.6627\n",
      "RMS error on training batch 7900 : 80.8864\n",
      "RMS error on training batch 7910 : 78.3601\n",
      "RMS error on training batch 7920 : 45.6829\n",
      "RMS error on training batch 7930 : 23.238\n",
      "RMS error on training batch 7940 : 45.0181\n",
      "RMS error on training batch 7950 : 35.5375\n",
      "RMS error on training batch 7960 : 37.7481\n",
      "RMS error on training batch 7970 : 36.1553\n",
      "RMS error on training batch 7980 : 25.8876\n",
      "RMS error on training batch 7990 : 49.0965\n",
      "RMS error on training batch 8000 : 32.2758\n",
      "RMS error on training batch 8010 : 27.369\n",
      "RMS error on training batch 8020 : 41.4509\n",
      "RMS error on training batch 8030 : 24.6262\n",
      "RMS error on training batch 8040 : 69.1008\n",
      "RMS error on training batch 8050 : 36.9563\n",
      "RMS error on training batch 8060 : 47.5737\n",
      "RMS error on training batch 8070 : 26.2778\n",
      "RMS error on training batch 8080 : 53.5355\n",
      "RMS error on training batch 8090 : 46.5703\n",
      "RMS error on training batch 8100 : 37.9351\n",
      "RMS error on training batch 8110 : 51.8275\n",
      "RMS error on training batch 8120 : 51.5309\n",
      "RMS error on training batch 8130 : 27.9385\n",
      "RMS error on training batch 8140 : 30.6951\n",
      "RMS error on training batch 8150 : 27.382\n",
      "RMS error on training batch 8160 : 24.9041\n",
      "RMS error on training batch 8170 : 33.6159\n",
      "RMS error on training batch 8180 : 54.0187\n",
      "RMS error on training batch 8190 : 32.8996\n",
      "RMS error on training batch 8200 : 28.3816\n",
      "RMS error on training batch 8210 : 46.6311\n",
      "RMS error on training batch 8220 : 46.4271\n",
      "RMS error on training batch 8230 : 17.7306\n",
      "RMS error on training batch 8240 : 24.5118\n",
      "RMS error on training batch 8250 : 49.8214\n",
      "RMS error on training batch 8260 : 17.5835\n",
      "RMS error on training batch 8270 : 22.4786\n",
      "RMS error on training batch 8280 : 33.6826\n",
      "RMS error on training batch 8290 : 62.5718\n",
      "RMS error on training batch 8300 : 44.2334\n",
      "RMS error on training batch 8310 : 41.7493\n",
      "RMS error on training batch 8320 : 30.254\n",
      "RMS error on training batch 8330 : 71.6287\n",
      "RMS error on training batch 8340 : 34.2188\n",
      "RMS error on training batch 8350 : 45.095\n",
      "RMS error on training batch 8360 : 45.0391\n",
      "RMS error on training batch 8370 : 22.5642\n",
      "RMS error on training batch 8380 : 70.8081\n",
      "RMS error on training batch 8390 : 110.523\n",
      "RMS error on training batch 8400 : 24.8031\n",
      "RMS error on training batch 8410 : 64.6958\n",
      "RMS error on training batch 8420 : 57.0456\n",
      "RMS error on training batch 8430 : 46.9068\n",
      "RMS error on training batch 8440 : 40.8693\n",
      "RMS error on training batch 8450 : 28.9488\n",
      "RMS error on training batch 8460 : 65.6599\n",
      "RMS error on training batch 8470 : 27.4695\n",
      "RMS error on training batch 8480 : 49.2074\n",
      "RMS error on training batch 8490 : 96.6402\n",
      "RMS error on training batch 8500 : 51.005\n",
      "RMS error on training batch 8510 : 95.078\n",
      "RMS error on training batch 8520 : 62.8648\n",
      "RMS error on training batch 8530 : 85.0448\n",
      "RMS error on training batch 8540 : 18.9598\n",
      "RMS error on training batch 8550 : 46.492\n",
      "RMS error on training batch 8560 : 36.4175\n",
      "RMS error on training batch 8570 : 28.2219\n",
      "RMS error on training batch 8580 : 36.1418\n",
      "RMS error on training batch 8590 : 70.6804\n",
      "RMS error on training batch 8600 : 33.818\n",
      "RMS error on training batch 8610 : 37.9656\n",
      "RMS error on training batch 8620 : 29.4455\n",
      "RMS error on training batch 8630 : 56.6183\n",
      "RMS error on training batch 8640 : 59.7654\n",
      "RMS error on training batch 8650 : 71.9069\n",
      "RMS error on training batch 8660 : 46.6062\n",
      "RMS error on training batch 8670 : 32.594\n",
      "RMS error on training batch 8680 : 18.3635\n",
      "RMS error on training batch 8690 : 37.0383\n",
      "RMS error on training batch 8700 : 74.2772\n",
      "RMS error on training batch 8710 : 91.0836\n",
      "RMS error on training batch 8720 : 36.4292\n",
      "RMS error on training batch 8730 : 37.8632\n",
      "RMS error on training batch 8740 : 27.3418\n",
      "RMS error on training batch 8750 : 22.9326\n",
      "RMS error on training batch 8760 : 41.5092\n",
      "RMS error on training batch 8770 : 39.1923\n",
      "RMS error on training batch 8780 : 24.7126\n",
      "RMS error on training batch 8790 : 19.0949\n",
      "RMS error on training batch 8800 : 65.2663\n",
      "RMS error on training batch 8810 : 55.8501\n",
      "RMS error on training batch 8820 : 33.004\n",
      "RMS error on training batch 8830 : 61.3699\n",
      "RMS error on training batch 8840 : 48.2941\n",
      "RMS error on training batch 8850 : 41.7349\n",
      "RMS error on training batch 8860 : 35.5149\n",
      "RMS error on training batch 8870 : 25.4037\n",
      "RMS error on training batch 8880 : 36.8261\n",
      "RMS error on training batch 8890 : 30.9101\n",
      "RMS error on training batch 8900 : 22.424\n",
      "RMS error on training batch 8910 : 29.5188\n",
      "RMS error on training batch 8920 : 28.3934\n",
      "RMS error on training batch 8930 : 37.5079\n",
      "RMS error on training batch 8940 : 33.2275\n",
      "RMS error on training batch 8950 : 96.429\n",
      "RMS error on training batch 8960 : 53.5872\n",
      "RMS error on training batch 8970 : 21.5696\n",
      "RMS error on training batch 8980 : 51.1265\n",
      "RMS error on training batch 8990 : 34.889\n",
      "RMS error on training batch 9000 : 44.0549\n",
      "RMS error on training batch 9010 : 72.6289\n",
      "RMS error on training batch 9020 : 32.5098\n",
      "RMS error on training batch 9030 : 21.4261\n",
      "RMS error on training batch 9040 : 19.2291\n",
      "RMS error on training batch 9050 : 19.8386\n",
      "RMS error on training batch 9060 : 47.3635\n",
      "RMS error on training batch 9070 : 28.8688\n",
      "RMS error on training batch 9080 : 43.1386\n",
      "RMS error on training batch 9090 : 37.8642\n",
      "RMS error on training batch 9100 : 25.2901\n",
      "RMS error on training batch 9110 : 68.3051\n",
      "RMS error on training batch 9120 : 35.4717\n",
      "RMS error on training batch 9130 : 29.5943\n",
      "RMS error on training batch 9140 : 37.2212\n",
      "RMS error on training batch 9150 : 22.9947\n",
      "RMS error on training batch 9160 : 33.1242\n",
      "RMS error on training batch 9170 : 27.0764\n",
      "RMS error on training batch 9180 : 41.6394\n",
      "RMS error on training batch 9190 : 36.7661\n",
      "RMS error on training batch 9200 : 46.5107\n",
      "RMS error on training batch 9210 : 27.5928\n",
      "RMS error on training batch 9220 : 44.0176\n",
      "RMS error on training batch 9230 : 16.8373\n",
      "RMS error on training batch 9240 : 39.2667\n",
      "RMS error on training batch 9250 : 18.9053\n",
      "RMS error on training batch 9260 : 45.4745\n",
      "RMS error on training batch 9270 : 34.3462\n",
      "RMS error on training batch 9280 : 42.7431\n",
      "RMS error on training batch 9290 : 71.9635\n",
      "RMS error on training batch 9300 : 80.3278\n",
      "RMS error on training batch 9310 : 109.038\n",
      "RMS error on training batch 9320 : 50.9769\n",
      "RMS error on training batch 9330 : 22.2195\n",
      "RMS error on training batch 9340 : 26.595\n",
      "RMS error on training batch 9350 : 98.8986\n",
      "RMS error on training batch 9360 : 18.0505\n",
      "RMS error on training batch 9370 : 67.5395\n",
      "RMS error on training batch 9380 : 108.483\n",
      "RMS error on training batch 9390 : 92.711\n",
      "RMS error on training batch 9400 : 37.4866\n",
      "RMS error on training batch 9410 : 36.9249\n",
      "RMS error on training batch 9420 : 44.8356\n",
      "RMS error on training batch 9430 : 20.9385\n",
      "RMS error on training batch 9440 : 42.6042\n",
      "RMS error on training batch 9450 : 54.6312\n",
      "RMS error on training batch 9460 : 38.9844\n",
      "RMS error on training batch 9470 : 71.54\n",
      "RMS error on training batch 9480 : 37.0707\n",
      "RMS error on training batch 9490 : 64.8835\n",
      "RMS error on training batch 9500 : 24.3493\n",
      "RMS error on training batch 9510 : 17.9826\n",
      "RMS error on training batch 9520 : 25.0476\n",
      "RMS error on training batch 9530 : 100.066\n",
      "RMS error on training batch 9540 : 53.4373\n",
      "RMS error on training batch 9550 : 24.1688\n",
      "RMS error on training batch 9560 : 35.9015\n",
      "RMS error on training batch 9570 : 33.4406\n",
      "RMS error on training batch 9580 : 33.2417\n",
      "RMS error on training batch 9590 : 25.7452\n",
      "RMS error on training batch 9600 : 23.5205\n",
      "RMS error on training batch 9610 : 17.1234\n",
      "RMS error on training batch 9620 : 39.6818\n",
      "RMS error on training batch 9630 : 30.8496\n",
      "RMS error on training batch 9640 : 27.5584\n",
      "RMS error on training batch 9650 : 33.644\n",
      "RMS error on training batch 9660 : 55.0261\n",
      "RMS error on training batch 9670 : 45.9735\n",
      "RMS error on training batch 9680 : 43.8086\n",
      "RMS error on training batch 9690 : 21.6197\n",
      "RMS error on training batch 9700 : 39.2303\n",
      "RMS error on training batch 9710 : 40.516\n",
      "RMS error on training batch 9720 : 63.2032\n",
      "RMS error on training batch 9730 : 44.4273\n",
      "RMS error on training batch 9740 : 47.2937\n",
      "RMS error on training batch 9750 : 68.5164\n",
      "RMS error on training batch 9760 : 51.8205\n",
      "RMS error on training batch 9770 : 72.91\n",
      "RMS error on training batch 9780 : 21.6757\n",
      "RMS error on training batch 9790 : 40.3923\n",
      "RMS error on training batch 9800 : 24.3194\n",
      "RMS error on training batch 9810 : 39.5673\n",
      "RMS error on training batch 9820 : 28.552\n",
      "RMS error on training batch 9830 : 39.9012\n",
      "RMS error on training batch 9840 : 24.9549\n",
      "RMS error on training batch 9850 : 67.3326\n",
      "RMS error on training batch 9860 : 25.1862\n",
      "RMS error on training batch 9870 : 16.4103\n",
      "RMS error on training batch 9880 : 34.7058\n",
      "RMS error on training batch 9890 : 44.526\n",
      "RMS error on training batch 9900 : 40.4996\n",
      "RMS error on training batch 9910 : 24.7486\n",
      "RMS error on training batch 9920 : 28.6838\n",
      "RMS error on training batch 9930 : 33.9936\n",
      "RMS error on training batch 9940 : 32.7572\n",
      "RMS error on training batch 9950 : 70.2176\n",
      "RMS error on training batch 9960 : 32.1809\n",
      "RMS error on training batch 9970 : 66.0412\n",
      "RMS error on training batch 9980 : 35.4338\n",
      "RMS error on training batch 9990 : 35.4129\n",
      "RMS error on training batch 10000 : 30.874\n",
      "RMS error on training batch 10010 : 23.6176\n",
      "RMS error on training batch 10020 : 26.3386\n",
      "RMS error on training batch 10030 : 40.2784\n",
      "RMS error on training batch 10040 : 29.6506\n",
      "RMS error on training batch 10050 : 31.9852\n",
      "RMS error on training batch 10060 : 22.4334\n",
      "RMS error on training batch 10070 : 24.6829\n",
      "RMS error on training batch 10080 : 28.4597\n",
      "RMS error on training batch 10090 : 14.0279\n",
      "RMS error on training batch 10100 : 24.0157\n",
      "RMS error on training batch 10110 : 20.6597\n",
      "RMS error on training batch 10120 : 43.7135\n",
      "RMS error on training batch 10130 : 29.9297\n",
      "RMS error on training batch 10140 : 55.048\n",
      "RMS error on training batch 10150 : 29.8971\n",
      "RMS error on training batch 10160 : 48.0941\n",
      "RMS error on training batch 10170 : 46.289\n",
      "RMS error on training batch 10180 : 33.5696\n",
      "RMS error on training batch 10190 : 46.9245\n",
      "RMS error on training batch 10200 : 94.2533\n",
      "RMS error on training batch 10210 : 22.0718\n",
      "RMS error on training batch 10220 : 49.095\n",
      "RMS error on training batch 10230 : 30.6752\n",
      "RMS error on training batch 10240 : 27.4147\n",
      "RMS error on training batch 10250 : 29.2704\n",
      "RMS error on training batch 10260 : 42.4628\n",
      "RMS error on training batch 10270 : 22.8074\n",
      "RMS error on training batch 10280 : 16.4237\n",
      "RMS error on training batch 10290 : 31.5092\n",
      "RMS error on training batch 10300 : 41.3396\n",
      "RMS error on training batch 10310 : 53.5441\n",
      "RMS error on training batch 10320 : 64.5955\n",
      "RMS error on training batch 10330 : 36.0336\n",
      "RMS error on training batch 10340 : 26.0214\n",
      "RMS error on training batch 10350 : 17.6096\n",
      "RMS error on training batch 10360 : 28.1455\n",
      "RMS error on training batch 10370 : 26.8698\n",
      "RMS error on training batch 10380 : 32.5512\n",
      "RMS error on training batch 10390 : 31.3144\n",
      "RMS error on training batch 10400 : 25.782\n",
      "RMS error on training batch 10410 : 32.3196\n",
      "RMS error on training batch 10420 : 23.616\n",
      "RMS error on training batch 10430 : 28.5654\n",
      "RMS error on training batch 10440 : 36.8586\n",
      "RMS error on training batch 10450 : 79.6497\n",
      "RMS error on training batch 10460 : 52.367\n",
      "RMS error on training batch 10470 : 41.5193\n",
      "RMS error on training batch 10480 : 26.2437\n",
      "RMS error on training batch 10490 : 57.0037\n",
      "RMS error on training batch 10500 : 22.1377\n",
      "RMS error on training batch 10510 : 15.3672\n",
      "RMS error on training batch 10520 : 30.1562\n",
      "RMS error on training batch 10530 : 31.1783\n",
      "RMS error on training batch 10540 : 26.0278\n",
      "RMS error on training batch 10550 : 19.7875\n",
      "RMS error on training batch 10560 : 39.3786\n",
      "RMS error on training batch 10570 : 32.0035\n",
      "RMS error on training batch 10580 : 39.5739\n",
      "RMS error on training batch 10590 : 41.6635\n",
      "RMS error on training batch 10600 : 31.1432\n",
      "RMS error on training batch 10610 : 27.2343\n",
      "RMS error on training batch 10620 : 16.1878\n",
      "RMS error on training batch 10630 : 32.8612\n",
      "RMS error on training batch 10640 : 25.3603\n",
      "RMS error on training batch 10650 : 29.005\n",
      "RMS error on training batch 10660 : 29.6906\n",
      "RMS error on training batch 10670 : 22.9144\n",
      "RMS error on training batch 10680 : 20.1873\n",
      "RMS error on training batch 10690 : 19.4052\n",
      "RMS error on training batch 10700 : 38.0362\n",
      "RMS error on training batch 10710 : 48.251\n",
      "RMS error on training batch 10720 : 73.0512\n",
      "RMS error on training batch 10730 : 30.5189\n",
      "RMS error on training batch 10740 : 32.9675\n",
      "RMS error on training batch 10750 : 26.2224\n",
      "RMS error on training batch 10760 : 42.6193\n",
      "RMS error on training batch 10770 : 37.4269\n",
      "RMS error on training batch 10780 : 24.9231\n",
      "RMS error on training batch 10790 : 19.3768\n",
      "RMS error on training batch 10800 : 54.9382\n",
      "RMS error on training batch 10810 : 46.0777\n",
      "RMS error on training batch 10820 : 16.2905\n",
      "RMS error on training batch 10830 : 56.5112\n",
      "RMS error on training batch 10840 : 43.8628\n",
      "RMS error on training batch 10850 : 28.9346\n",
      "RMS error on training batch 10860 : 37.7201\n",
      "RMS error on training batch 10870 : 27.9467\n",
      "RMS error on training batch 10880 : 17.9802\n",
      "RMS error on training batch 10890 : 35.3206\n",
      "RMS error on training batch 10900 : 30.9467\n",
      "RMS error on training batch 10910 : 20.3664\n",
      "RMS error on training batch 10920 : 41.3368\n",
      "RMS error on training batch 10930 : 37.4463\n",
      "RMS error on training batch 10940 : 22.947\n",
      "RMS error on training batch 10950 : 25.3501\n",
      "RMS error on training batch 10960 : 32.9416\n",
      "RMS error on training batch 10970 : 50.7588\n",
      "RMS error on training batch 10980 : 30.6303\n",
      "RMS error on training batch 10990 : 37.1839\n",
      "RMS error on training batch 11000 : 21.6825\n",
      "RMS error on training batch 11010 : 27.4578\n",
      "RMS error on training batch 11020 : 20.7713\n",
      "RMS error on training batch 11030 : 30.8182\n",
      "RMS error on training batch 11040 : 29.4984\n",
      "RMS error on training batch 11050 : 38.5447\n",
      "RMS error on training batch 11060 : 19.5218\n",
      "RMS error on training batch 11070 : 69.0015\n",
      "RMS error on training batch 11080 : 51.7869\n",
      "RMS error on training batch 11090 : 31.5355\n",
      "RMS error on training batch 11100 : 48.5671\n",
      "RMS error on training batch 11110 : 42.6667\n",
      "RMS error on training batch 11120 : 54.6214\n",
      "RMS error on training batch 11130 : 35.2934\n",
      "RMS error on training batch 11140 : 12.5708\n",
      "RMS error on training batch 11150 : 37.4843\n",
      "RMS error on training batch 11160 : 48.1428\n",
      "RMS error on training batch 11170 : 59.9905\n",
      "RMS error on training batch 11180 : 65.4941\n",
      "RMS error on training batch 11190 : 32.5103\n",
      "RMS error on training batch 11200 : 57.372\n",
      "RMS error on training batch 11210 : 33.5002\n",
      "RMS error on training batch 11220 : 46.1744\n",
      "RMS error on training batch 11230 : 42.5094\n",
      "RMS error on training batch 11240 : 77.4762\n",
      "RMS error on training batch 11250 : 61.1631\n",
      "RMS error on training batch 11260 : 28.2697\n",
      "RMS error on training batch 11270 : 26.1556\n",
      "RMS error on training batch 11280 : 24.1708\n",
      "RMS error on training batch 11290 : 25.7187\n",
      "RMS error on training batch 11300 : 34.1393\n",
      "RMS error on training batch 11310 : 27.7231\n",
      "RMS error on training batch 11320 : 42.8844\n",
      "RMS error on training batch 11330 : 23.8276\n",
      "RMS error on training batch 11340 : 25.0624\n",
      "RMS error on training batch 11350 : 34.9833\n",
      "RMS error on training batch 11360 : 21.232\n",
      "RMS error on training batch 11370 : 39.6222\n",
      "RMS error on training batch 11380 : 21.5937\n",
      "RMS error on training batch 11390 : 59.3066\n",
      "RMS error on training batch 11400 : 27.0657\n",
      "RMS error on training batch 11410 : 26.2059\n",
      "RMS error on training batch 11420 : 70.7307\n",
      "RMS error on training batch 11430 : 80.0\n",
      "RMS error on training batch 11440 : 29.6118\n",
      "RMS error on training batch 11450 : 33.3333\n",
      "RMS error on training batch 11460 : 69.5264\n",
      "RMS error on training batch 11470 : 15.6599\n",
      "RMS error on training batch 11480 : 36.6409\n",
      "RMS error on training batch 11490 : 48.4208\n",
      "RMS error on training batch 11500 : 38.019\n",
      "RMS error on training batch 11510 : 38.2592\n",
      "RMS error on training batch 11520 : 31.6156\n",
      "RMS error on training batch 11530 : 59.3986\n",
      "RMS error on training batch 11540 : 16.8045\n",
      "RMS error on training batch 11550 : 31.4598\n",
      "RMS error on training batch 11560 : 31.3175\n",
      "RMS error on training batch 11570 : 46.8119\n",
      "RMS error on training batch 11580 : 58.7865\n",
      "RMS error on training batch 11590 : 58.7714\n",
      "RMS error on training batch 11600 : 21.6175\n",
      "RMS error on training batch 11610 : 18.1552\n",
      "RMS error on training batch 11620 : 38.4384\n",
      "RMS error on training batch 11630 : 29.666\n",
      "RMS error on training batch 11640 : 28.3882\n",
      "RMS error on training batch 11650 : 30.7536\n",
      "RMS error on training batch 11660 : 85.0087\n",
      "RMS error on training batch 11670 : 69.7803\n",
      "RMS error on training batch 11680 : 37.9168\n",
      "RMS error on training batch 11690 : 19.7647\n",
      "RMS error on training batch 11700 : 46.1325\n",
      "RMS error on training batch 11710 : 77.3971\n",
      "RMS error on training batch 11720 : 26.8113\n",
      "RMS error on training batch 11730 : 19.5629\n",
      "RMS error on training batch 11740 : 17.8131\n",
      "RMS error on training batch 11750 : 13.4049\n",
      "RMS error on training batch 11760 : 66.6917\n",
      "RMS error on training batch 11770 : 49.4581\n",
      "RMS error on training batch 11780 : 46.8591\n",
      "RMS error on training batch 11790 : 55.6737\n",
      "RMS error on training batch 11800 : 27.1816\n",
      "RMS error on training batch 11810 : 52.8212\n",
      "RMS error on training batch 11820 : 65.3489\n",
      "RMS error on training batch 11830 : 41.3387\n",
      "RMS error on training batch 11840 : 32.4118\n",
      "RMS error on training batch 11850 : 33.537\n",
      "RMS error on training batch 11860 : 54.7906\n",
      "RMS error on training batch 11870 : 39.805\n",
      "RMS error on training batch 11880 : 21.4012\n",
      "RMS error on training batch 11890 : 13.6159\n",
      "RMS error on training batch 11900 : 42.8248\n",
      "RMS error on training batch 11910 : 55.2305\n",
      "RMS error on training batch 11920 : 58.6319\n",
      "RMS error on training batch 11930 : 55.3254\n",
      "RMS error on training batch 11940 : 58.4451\n",
      "RMS error on training batch 11950 : 48.101\n",
      "RMS error on training batch 11960 : 27.648\n",
      "RMS error on training batch 11970 : 51.5524\n",
      "RMS error on training batch 11980 : 14.591\n",
      "RMS error on training batch 11990 : 29.1397\n",
      "RMS error on training batch 12000 : 32.8481\n",
      "RMS error on training batch 12010 : 43.1767\n",
      "RMS error on training batch 12020 : 42.1534\n",
      "RMS error on training batch 12030 : 25.4078\n",
      "RMS error on training batch 12040 : 60.5428\n",
      "RMS error on training batch 12050 : 35.3822\n",
      "RMS error on training batch 12060 : 41.2823\n",
      "RMS error on training batch 12070 : 31.1874\n",
      "RMS error on training batch 12080 : 28.0757\n",
      "RMS error on training batch 12090 : 87.8947\n",
      "RMS error on training batch 12100 : 63.9166\n",
      "RMS error on training batch 12110 : 30.618\n",
      "RMS error on training batch 12120 : 42.0998\n",
      "RMS error on training batch 12130 : 11.2525\n",
      "RMS error on training batch 12140 : 33.3734\n",
      "RMS error on training batch 12150 : 33.4793\n",
      "RMS error on training batch 12160 : 15.0952\n",
      "RMS error on training batch 12170 : 38.1399\n",
      "RMS error on training batch 12180 : 24.0018\n",
      "RMS error on training batch 12190 : 23.1754\n",
      "RMS error on training batch 12200 : 45.3273\n",
      "RMS error on training batch 12210 : 47.7151\n",
      "RMS error on training batch 12220 : 31.1005\n",
      "RMS error on training batch 12230 : 38.5864\n",
      "RMS error on training batch 12240 : 54.6936\n",
      "RMS error on training batch 12250 : 37.9363\n",
      "RMS error on training batch 12260 : 38.1551\n",
      "RMS error on training batch 12270 : 33.4096\n",
      "RMS error on training batch 12280 : 43.4703\n",
      "RMS error on training batch 12290 : 20.6747\n",
      "RMS error on training batch 12300 : 24.7786\n",
      "RMS error on training batch 12310 : 31.822\n",
      "RMS error on training batch 12320 : 26.8134\n",
      "RMS error on training batch 12330 : 27.0058\n",
      "RMS error on training batch 12340 : 57.3933\n",
      "RMS error on training batch 12350 : 19.9113\n",
      "RMS error on training batch 12360 : 85.2384\n",
      "RMS error on training batch 12370 : 35.3862\n",
      "RMS error on training batch 12380 : 54.9472\n",
      "RMS error on training batch 12390 : 26.3267\n",
      "RMS error on training batch 12400 : 22.4733\n",
      "RMS error on training batch 12410 : 23.3063\n",
      "RMS error on training batch 12420 : 54.3005\n",
      "RMS error on training batch 12430 : 16.7727\n",
      "RMS error on training batch 12440 : 45.8107\n",
      "RMS error on training batch 12450 : 57.0967\n",
      "RMS error on training batch 12460 : 41.322\n",
      "RMS error on training batch 12470 : 27.5004\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-424ee9bd49b7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m10\u001b[0m \u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         train_error = accuracy.eval(feed_dict={\n\u001b[0;32m----> 6\u001b[0;31m         x:batch[0], y_: batch[1], keep_prob: 1.0})\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0;32mprint\u001b[0m \u001b[0;34m'RMS error on training batch'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m':'\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mtrain_error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mtrain_step\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkeep_prob\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36meval\u001b[0;34m(self, feed_dict, session)\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m     \"\"\"\n\u001b[0;32m--> 555\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_eval_using_default_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    556\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36m_eval_using_default_session\u001b[0;34m(tensors, feed_dict, graph, session)\u001b[0m\n\u001b[1;32m   3496\u001b[0m                        \u001b[0;34m\"the tensor's graph is different from the session's \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3497\u001b[0m                        \"graph.\")\n\u001b[0;32m-> 3498\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3500\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    370\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 372\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    373\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    634\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m       results = self._do_run(handle, target_list, unique_fetches,\n\u001b[0;32m--> 636\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    637\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    638\u001b[0m       \u001b[0;31m# The movers are no longer used. Delete them.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    706\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m--> 708\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m    709\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m    713\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    714\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 715\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    716\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    717\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m    695\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m    696\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 697\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m    698\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(10000):\n",
    "    pts = np.random.randint(0,1000,size=50)\n",
    "    batch = (X[pts].flatten().reshape(50,10880), training_centers[pts].flatten().reshape(50,2))\n",
    "    if i%10 ==0:\n",
    "        train_error = accuracy.eval(feed_dict={\n",
    "        x:batch[0], y_: batch[1], keep_prob: 1.0})\n",
    "        print 'RMS error on training batch',i, ':',  train_error\n",
    "    train_step.run(feed_dict={x:batch[0],y_:batch[1],keep_prob: 0.5})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_test_data(num_images):\n",
    "    data=[]\n",
    "    for i in range(1000,num_images+1000):\n",
    "        if i%100 ==0:\n",
    "            print 'Reading patch ', i\n",
    "        ultra_image = smp.image_pair(non_empty_training.ix[i].subject,non_empty_training.ix[i].img).image\n",
    "        data.append(reduce(ultra_image)[25:,:136].flatten())\n",
    "    return np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'saver' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-0f77fc92fd5f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msaved_model\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0msaver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"/Users/gus/CDIPS/nerve-project/\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'saver' is not defined"
     ]
    }
   ],
   "source": [
    "saved_model  = saver.save(sess, \"/Users/gus/CDIPS/nerve-project/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading patch  1000\n",
      "Reading patch  1100\n"
     ]
    }
   ],
   "source": [
    "time x_test=build_test_data(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 10880)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_centers=center_list[1000:2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_centers' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-846a8bf956f6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_centers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'test_centers' is not defined"
     ]
    }
   ],
   "source": [
    "test_centers.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"test rms error %g\"%accuracy.eval(feed_dict={\n",
    "    x: x_test, y_: test_centers, keep_prob: 1.0}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
