{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import skimage\n",
    "from skimage import io, feature, measure, transform\n",
    "import tensorflow as tf\n",
    "from pandas import Series,DataFrame\n",
    "import sampling as smp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sess=tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### x will contain flattened 35 x 35 pixel patches as rows\n",
    "### placeholder None is there to allow us to have arbitrary number of training ex.\n",
    "### y will contain 1-hot patch labels\n",
    "\n",
    "\n",
    "x= tf.placeholder(tf.float32,shape=[None,1225])\n",
    "x_image = tf.reshape(x, [-1,35,35,1])\n",
    "y_ = tf.placeholder(tf.float32, shape=[None, 50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### helper fn for random positive initialization of weights\n",
    "def weight_variable(shape):\n",
    "  initial = tf.truncated_normal(shape, stddev=1)\n",
    "  return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "  initial = tf.constant(0.1, shape=shape)\n",
    "  return tf.Variable(initial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### helper functions to build Conv and MaxPool layers\n",
    "\n",
    "def conv2d(x, W):\n",
    "  return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "def max_pool(x,poolSize,strideSize):\n",
    "  return tf.nn.max_pool(x, ksize=[1, poolSize, poolSize, 1],\n",
    "                        strides=[1, strideSize, strideSize, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### weights and biases for the first Conv layer; 5x5 filter and 32 feat.\n",
    "W_conv1 = weight_variable([4, 4, 1, 32])\n",
    "b_conv1 = bias_variable([32])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### build first Conv and MaxPool layers\n",
    "h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\n",
    "h_pool1 = max_pool(h_conv1,3,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(18), Dimension(18), Dimension(32)])"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h_pool1.get_shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### weights and biases for the second Conv layer; 5x5 filter and  feat.\n",
    "W_conv2 = weight_variable([4, 4, 32, 64])\n",
    "b_conv2 = bias_variable([64])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### build second Conv and MaxPool layers\n",
    "h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "h_pool2 = max_pool(h_conv2,3,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(9), Dimension(9), Dimension(64)])"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h_pool2.get_shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### weights and biases for the third Conv layer; 5x5 filter and 128 feat.\n",
    "W_conv3 = weight_variable([4, 4, 64, 128])\n",
    "b_conv3 = bias_variable([128])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### build third Conv and MaxPool layers\n",
    "h_conv3 = tf.nn.relu(conv2d(h_pool2,W_conv3)+b_conv3)\n",
    "h_pool3 =max_pool(h_conv3,3,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(5), Dimension(5), Dimension(128)])"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h_pool3.get_shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### add fully-connected layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "W_fc = weight_variable([5 * 5 * 128, 128])\n",
    "b_fc = bias_variable([128])\n",
    "\n",
    "h_pool3_flat = tf.reshape(h_pool3, [-1, 5*5*128])\n",
    "h_fc = tf.nn.relu(tf.matmul(h_pool3_flat, W_fc) + b_fc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### dropout before output layer\n",
    "\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "h_fc_drop = tf.nn.dropout(h_fc, keep_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### output layer\n",
    "\n",
    "W_out = weight_variable([128,50])\n",
    "b_out = bias_variable([50])\n",
    "\n",
    "y_conv = tf.nn.softmax(tf.matmul(h_fc_drop, W_out) + b_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(50)])"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_conv.get_shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "####  cross entropy cost function\n",
    "softmax_cost_fn = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(tf.clip_by_value(y_conv,1e-10,1.0)), reduction_indices=[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### positive-shared cost function from the DeepContour paper\n",
    "\n",
    "modified_cost_fn = softmax_cost_fn-tf.reduce_mean(y_[:,0]*tf.log(tf.clip_by_value(y_conv,1e-10,1.0))[:,0] + tf.reduce_sum(tf.transpose(tf.transpose(y_[:,1:])*tf.log(tf.clip_by_value(y_conv,1e-10,1.0)[:,0])),reduction_indices=[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### the training step\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(modified_cost_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### accuracy\n",
    "correct_prediction = tf.equal(tf.argmax(y_conv,1), tf.argmax(y_,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### contrast score from eqn (7) in DeepContour paper. This is broken but can't figure out how...\n",
    "\n",
    "contrast = tf.reduce_mean((y_[:,0] - tf.reduce_sum(y_[:,1:],reduction_indices=[1])) * (2*y_conv[:,0]-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### build a batch for the optimizer\n",
    "\n",
    "def build_batch(X,y,b_size):\n",
    "    m = X.shape[0]\n",
    "    pts = np.random.randint(0,m,size=b_size)\n",
    "    batch = (X[pts].flatten().reshape(b_size,35*35), y[pts].flatten().reshape(b_size,50))\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "########              Training the network               ########\n",
    "####  the input image patches are in 'ultra_training.msg'     ###\n",
    "####  the cluster labels are in 'permuted_cluster_label_training.msg'  ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#### load the training data\n",
    "X = pd.read_msgpack('ultra_training.msg').as_matrix()[:6000,:] \n",
    "labels = pd.read_msgpack('permuted_cluster_label_training.msg').as_matrix()[:6000,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#### start the session\n",
    "sess.run(tf.initialize_all_variables())\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, training contrast -0.12\n",
      "step 100, training contrast 0.12\n",
      "step 200, training contrast -0.32\n",
      "step 300, training contrast -0.04\n",
      "step 400, training contrast -0.16\n",
      "step 500, training contrast -0.32\n",
      "step 600, training contrast -0.28\n",
      "step 700, training contrast -0.12\n",
      "step 800, training contrast -0.12\n",
      "step 900, training contrast -0.2\n",
      "step 1000, training contrast -0.24\n",
      "step 1100, training contrast -0.16\n",
      "step 1200, training contrast -0.04\n",
      "step 1300, training contrast -0.24\n",
      "step 1400, training contrast -0.16\n",
      "step 1500, training contrast -0.16\n",
      "step 1600, training contrast -0.12\n",
      "step 1700, training contrast -0.32\n",
      "step 1800, training contrast -0.16\n",
      "step 1900, training contrast -0.08\n",
      "step 2000, training contrast -0.24\n",
      "step 2100, training contrast -0.24\n",
      "step 2200, training contrast -0.12\n",
      "step 2300, training contrast -0.16\n",
      "step 2400, training contrast -0.2\n",
      "step 2500, training contrast -0.28\n",
      "step 2600, training contrast -0.28\n",
      "step 2700, training contrast -0.16\n",
      "step 2800, training contrast -0.24\n",
      "step 2900, training contrast 0.04\n",
      "step 3000, training contrast -0.04\n",
      "step 3100, training contrast 0\n",
      "step 3200, training contrast -0.12\n",
      "step 3300, training contrast -0.32\n",
      "step 3400, training contrast -0.16\n",
      "step 3500, training contrast -0.32\n",
      "step 3600, training contrast -0.04\n",
      "step 3700, training contrast -0.28\n",
      "step 3800, training contrast -0.08\n",
      "step 3900, training contrast -0.08\n",
      "step 4000, training contrast -0.2\n",
      "step 4100, training contrast -0.2\n",
      "step 4200, training contrast -0.04\n",
      "step 4300, training contrast -0.24\n",
      "step 4400, training contrast -0.16\n",
      "step 4500, training contrast 0\n",
      "step 4600, training contrast -0.24\n",
      "step 4700, training contrast -0.12\n",
      "step 4800, training contrast -0.2\n",
      "step 4900, training contrast -0.16\n",
      "step 5000, training contrast 0\n",
      "step 5100, training contrast -0.48\n",
      "step 5200, training contrast -0.36\n",
      "step 5300, training contrast -0.24\n",
      "step 5400, training contrast 0\n",
      "step 5500, training contrast 0.12\n",
      "step 5600, training contrast -0.16\n",
      "step 5700, training contrast -0.2\n",
      "step 5800, training contrast -0.2\n",
      "step 5900, training contrast 0.12\n",
      "step 6000, training contrast 0\n",
      "step 6100, training contrast -0.32\n",
      "step 6200, training contrast -0.32\n",
      "step 6300, training contrast -0.08\n",
      "step 6400, training contrast -0.16\n",
      "step 6500, training contrast -0.24\n",
      "step 6600, training contrast -0.12\n",
      "step 6700, training contrast -0.04\n",
      "step 6800, training contrast -0.16\n",
      "step 6900, training contrast -0.48\n",
      "step 7000, training contrast -0.28\n",
      "step 7100, training contrast -0.16\n",
      "step 7200, training contrast 0.12\n",
      "step 7300, training contrast -0.08\n",
      "step 7400, training contrast 0.12\n",
      "step 7500, training contrast -0.12\n",
      "step 7600, training contrast -0.08\n",
      "step 7700, training contrast -0.32\n",
      "step 7800, training contrast -0.28\n",
      "step 7900, training contrast -0.2\n",
      "step 8000, training contrast 0.2\n",
      "step 8100, training contrast -0.04\n",
      "step 8200, training contrast -0.16\n",
      "step 8300, training contrast 0.16\n",
      "step 8400, training contrast 0.04\n",
      "step 8500, training contrast -0.08\n",
      "step 8600, training contrast -0.16\n",
      "step 8700, training contrast -0.04\n",
      "step 8800, training contrast 0.04\n",
      "step 8900, training contrast -0.04\n",
      "step 9000, training contrast -0.24\n",
      "step 9100, training contrast -0.2\n",
      "step 9200, training contrast 0\n",
      "step 9300, training contrast -0.12\n",
      "step 9400, training contrast -0.12\n",
      "step 9500, training contrast -0.4\n",
      "step 9600, training contrast 0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-183-c8a48f5dca0a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"step %d, training contrast %g\"\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_contrast\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     train_step.run(feed_dict={\n\u001b[0;32m---> 10\u001b[0;31m         x:batch[0], y_: batch[1],  keep_prob: 0.6})\n\u001b[0m",
      "\u001b[0;32m//anaconda/envs/CDIPS/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, feed_dict, session)\u001b[0m\n\u001b[1;32m   1375\u001b[0m         \u001b[0mnone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdefault\u001b[0m \u001b[0msession\u001b[0m \u001b[0mwill\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mused\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1376\u001b[0m     \"\"\"\n\u001b[0;32m-> 1377\u001b[0;31m     \u001b[0m_run_using_default_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1379\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/envs/CDIPS/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_run_using_default_session\u001b[0;34m(operation, feed_dict, graph, session)\u001b[0m\n\u001b[1;32m   3130\u001b[0m                        \u001b[0;34m\"the operation's graph is different from the session's \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3131\u001b[0m                        \"graph.\")\n\u001b[0;32m-> 3132\u001b[0;31m   \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/envs/CDIPS/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict)\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;31m`\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mdoesn\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0mt\u001b[0m \u001b[0mexist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m     \"\"\"\n\u001b[0;32m--> 315\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mpartial_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/envs/CDIPS/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict)\u001b[0m\n\u001b[1;32m    509\u001b[0m     \u001b[0;31m# Run request and get response.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m     results = self._do_run(handle, target_list, unique_fetches,\n\u001b[0;32m--> 511\u001b[0;31m                            feed_dict_string)\n\u001b[0m\u001b[1;32m    512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m     \u001b[0;31m# User may have fetched the same tensor multiple times, but we\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/envs/CDIPS/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict)\u001b[0m\n\u001b[1;32m    562\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m--> 564\u001b[0;31m                            target_list)\n\u001b[0m\u001b[1;32m    565\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m//anaconda/envs/CDIPS/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m    569\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 571\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    572\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStatusNotOK\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m       \u001b[0me_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me_traceback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/envs/CDIPS/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list)\u001b[0m\n\u001b[1;32m    553\u001b[0m       \u001b[0;31m# Ensure any changes to the graph are reflected in the runtime.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    556\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(10000):\n",
    "    batch = build_batch(X,labels,50)\n",
    "    if i%100 == 0:\n",
    "        train_acc = accuracy.eval(feed_dict={\n",
    "        x:batch[0], y_: batch[1],  keep_prob: 1.0})\n",
    "        train_contrast = contrast.eval(feed_dict={\n",
    "        x:batch[0], y_: batch[1],  keep_prob: 1.0})\n",
    "        print(\"step %d, training contrast %g\"%(i, train_contrast))\n",
    "    train_step.run(feed_dict={\n",
    "        x:batch[0], y_: batch[1],  keep_prob: 0.6})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#save_path = saver.save(sess, \"/Users/gus/CDIPS/uns/patch_trained_1.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_output = y_conv.eval(feed_dict={x:X[6000:7000,:],y_:labels[6000:7000,:],keep_prob:1.0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_accuracy = accuracy.eval(feed_dict={x:X[6000:7000,:],y_:labels[6000:7000,:],keep_prob:1.0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [CDIPS]",
   "language": "python",
   "name": "Python [CDIPS]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
