{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import bottlenecking as btl\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import uns\n",
    "from uns import training\n",
    "import fcn16_vgg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_images = tf.placeholder(tf.float32,[None,420,580,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vgg_path = '../tensorflow-fcn/vgg16.npy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "npy file loaded\n"
     ]
    }
   ],
   "source": [
    "net = fcn16_vgg.FCN16VGG(vgg16_npy_path=vgg_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer name: conv1_1\n",
      "Layer shape: (3, 3, 3, 64)\n",
      "Layer name: conv1_2\n",
      "Layer shape: (3, 3, 64, 64)\n",
      "Layer name: conv2_1\n",
      "Layer shape: (3, 3, 64, 128)\n",
      "Layer name: conv2_2\n",
      "Layer shape: (3, 3, 128, 128)\n",
      "Layer name: conv3_1\n",
      "Layer shape: (3, 3, 128, 256)\n",
      "Layer name: conv3_2\n",
      "Layer shape: (3, 3, 256, 256)\n",
      "Layer name: conv3_3\n",
      "Layer shape: (3, 3, 256, 256)\n",
      "Layer name: conv4_1\n",
      "Layer shape: (3, 3, 256, 512)\n",
      "Layer name: conv4_2\n",
      "Layer shape: (3, 3, 512, 512)\n",
      "Layer name: conv4_3\n",
      "Layer shape: (3, 3, 512, 512)\n",
      "Layer name: conv5_1\n",
      "Layer shape: (3, 3, 512, 512)\n",
      "Layer name: conv5_2\n",
      "Layer shape: (3, 3, 512, 512)\n",
      "Layer name: conv5_3\n",
      "Layer shape: (3, 3, 512, 512)\n",
      "Layer name: fc6\n",
      "Layer shape: [7, 7, 512, 4096]\n",
      "Layer name: fc7\n",
      "Layer shape: [1, 1, 4096, 4096]\n"
     ]
    }
   ],
   "source": [
    "with tf.name_scope(\"content_vgg\"):\n",
    "       net.build(batch_images, train=False, num_classes=2, random_init_fc8=True,debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bottleneck=net.fc6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[14, 19, 4096]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "btl.get_bottleneck_dims(bottleneck)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_batch_output(input,path,bottleneck,sess):\n",
    "    \"\"\"writes a single batch to disk\"\"\"\n",
    "    batch_size = input.shape[0]\n",
    "    output = sess.run(bottleneck, feed_dict={batch_images:input})\n",
    "    print('Finished running forward passes')\n",
    "    data = np.save(path,output)\n",
    "    msg = 'Output data written to {file}'.format(file=path)\n",
    "    print(msg)\n",
    "\n",
    "\n",
    "def build_output_data(session,bottleneck,batch_size,trainingData,target_dir,name='fc6',debug=False):    \n",
    "    \"\"\"write a bunch of batches to disk\"\"\"\n",
    "    batches = btl.make_batches(trainingData,batch_size)\n",
    "    if debug == True:\n",
    "        batches = batches[:4]\n",
    "    for i,b in enumerate(batches):\n",
    "        images = btl.load_batch(b)\n",
    "        filename = target_dir+name +'_batch_' + str(i+1)\n",
    "        build_batch_output(images, filename,bottleneck,session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### test making first 12 training images into 4 batches of 3 images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.95 s, sys: 6.79 s, total: 10.7 s\n",
      "Wall time: 24.8 s\n"
     ]
    }
   ],
   "source": [
    "time sess.run(tf.initialize_all_variables())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/envs/CDIPS/lib/python3.5/site-packages/skimage/external/tifffile/tifffile.py:1794: RuntimeWarning: py_decodelzw encountered unexpected end of stream\n",
      "  strip = decompress(strip)\n"
     ]
    }
   ],
   "source": [
    "build_output_data(sess,bottleneck,4,training[:12],'/Users/gus/CDIPS/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [CDIPS]",
   "language": "python",
   "name": "Python [CDIPS]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
